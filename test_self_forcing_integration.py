#!/usr/bin/env python3
"""
Test script to verify self-forcing integration works correctly across all pipelines.
"""

import sys
import os
import tempfile
from pathlib import Path

sys.path.insert(0, os.path.abspath('.'))

def test_self_forcing_model_definition():
    """Test that self-forcing model is properly defined in model manager."""
    try:
        from backend.model_manager import VIDEO_MODELS, HF_MODEL_REPOS
        
        if "self_forcing" not in VIDEO_MODELS:
            print("‚ùå self_forcing not found in VIDEO_MODELS")
            return False
        
        model_def = VIDEO_MODELS["self_forcing"]
        required_fields = ["name", "description", "type", "size", "model_id", "resolution", "vram_requirement"]
        
        for field in required_fields:
            if field not in model_def:
                print(f"‚ùå Missing field '{field}' in self_forcing model definition")
                return False
        
        if "self_forcing" not in HF_MODEL_REPOS:
            print("‚ùå self_forcing not found in HF_MODEL_REPOS")
            return False
        
        if HF_MODEL_REPOS["self_forcing"] != "gdhe17/Self-Forcing":
            print("‚ùå Incorrect HuggingFace repository for self_forcing")
            return False
        
        print("‚úÖ Self-forcing model definition is correct")
        return True
        
    except Exception as e:
        print(f"‚ùå Error testing self-forcing model definition: {e}")
        return False

def test_text_to_video_generator_integration():
    """Test that TextToVideoGenerator properly integrates self-forcing."""
    try:
        from backend.pipelines.text_to_video_generator import TextToVideoGenerator
        
        generator = TextToVideoGenerator()
        
        if "self_forcing" not in generator.model_settings:
            print("‚ùå self_forcing not found in model_settings")
            return False
        
        sf_settings = generator.model_settings["self_forcing"]
        required_tiers = ["low", "medium", "high", "ultra"]
        
        for tier in required_tiers:
            if tier not in sf_settings:
                print(f"‚ùå Missing VRAM tier '{tier}' for self_forcing")
                return False
            
            tier_config = sf_settings[tier]
            required_config = ["max_frames", "resolution", "steps", "vram_req"]
            
            for config in required_config:
                if config not in tier_config:
                    print(f"‚ùå Missing config '{config}' in {tier} tier for self_forcing")
                    return False
        
        if not hasattr(generator, '_load_self_forcing'):
            print("‚ùå _load_self_forcing method not found")
            return False
        
        if not hasattr(generator, '_generate_self_forcing_video'):
            print("‚ùå _generate_self_forcing_video method not found")
            return False
        
        print("‚úÖ TextToVideoGenerator self-forcing integration is correct")
        return True
        
    except Exception as e:
        print(f"‚ùå Error testing TextToVideoGenerator integration: {e}")
        return False

def test_content_model_preferences():
    """Test that self-forcing is properly prioritized in content model preferences."""
    try:
        from backend.pipelines.text_to_video_generator import TextToVideoGenerator
        
        generator = TextToVideoGenerator()
        
        content_types = ["action", "combat", "dialogue", "exploration", "character_development", "default"]
        
        for content_type in content_types:
            best_model = generator.get_best_model_for_content(content_type, "high")
            
            print(f"‚úÖ Best model for {content_type}: {best_model}")
        
        print("‚úÖ Content model preferences include self-forcing")
        return True
        
    except Exception as e:
        print(f"‚ùå Error testing content model preferences: {e}")
        return False

def test_pipeline_compatibility():
    """Test that all channel pipelines can work with self-forcing through TextToVideoGenerator."""
    try:
        pipeline_classes = [
            ("anime", "backend.pipelines.channel_specific.anime_pipeline", "AnimeChannelPipeline"),
            ("gaming", "backend.pipelines.channel_specific.gaming_pipeline", "GamingChannelPipeline"),
            ("superhero", "backend.pipelines.channel_specific.superhero_pipeline", "SuperheroChannelPipeline"),
            ("manga", "backend.pipelines.channel_specific.manga_pipeline", "MangaChannelPipeline"),
            ("marvel_dc", "backend.pipelines.channel_specific.marvel_dc_pipeline", "MarvelDCChannelPipeline"),
            ("original_manga", "backend.pipelines.channel_specific.original_manga_pipeline", "OriginalMangaChannelPipeline")
        ]
        
        for channel_name, module_path, class_name in pipeline_classes:
            try:
                module = __import__(module_path, fromlist=[class_name])
                pipeline_class = getattr(module, class_name)
                
                with tempfile.TemporaryDirectory() as temp_dir:
                    try:
                        pipeline = pipeline_class(output_path=temp_dir)
                    except TypeError:
                        try:
                            pipeline = pipeline_class()
                            pipeline.current_output_dir = temp_dir
                        except:
                            print(f"‚ö†Ô∏è Could not initialize {channel_name} pipeline - constructor mismatch")
                            continue
                    
                    if hasattr(pipeline, 'video_generator'):
                        print(f"‚úÖ {channel_name} pipeline has video_generator")
                    else:
                        print(f"‚ö†Ô∏è {channel_name} pipeline missing video_generator (may be initialized later)")
                
                print(f"‚úÖ {channel_name} pipeline import and initialization successful")
                
            except Exception as e:
                print(f"‚ùå Error with {channel_name} pipeline: {e}")
                return False
        
        print("‚úÖ All channel pipelines are compatible with self-forcing integration")
        return True
        
    except Exception as e:
        print(f"‚ùå Error testing pipeline compatibility: {e}")
        return False

def test_model_path_mapping():
    """Test that self-forcing model path is correctly mapped."""
    try:
        from backend.pipelines.text_to_video_generator import TextToVideoGenerator
        
        generator = TextToVideoGenerator()
        
        model_path = generator._get_model_path("self_forcing")
        
        if model_path is None:
            print("‚ö†Ô∏è self_forcing model path not found (expected if model not downloaded)")
        else:
            print(f"‚úÖ self_forcing model path: {model_path}")
        
        print("‚úÖ Model path mapping includes self-forcing")
        return True
        
    except Exception as e:
        print(f"‚ùå Error testing model path mapping: {e}")
        return False

def test_prompt_optimization():
    """Test that prompt optimization includes self-forcing."""
    try:
        from backend.pipelines.text_to_video_generator import TextToVideoGenerator
        
        generator = TextToVideoGenerator()
        
        test_prompt = "A character walking through a forest"
        optimized = generator.optimize_prompt_for_model(test_prompt, "self_forcing", "action")
        
        if "real-time streaming" in optimized or "autoregressive" in optimized:
            print(f"‚úÖ Self-forcing prompt optimization working: {optimized[:100]}...")
        else:
            print(f"‚ö†Ô∏è Self-forcing prompt optimization may not be working: {optimized[:100]}...")
        
        print("‚úÖ Prompt optimization includes self-forcing")
        return True
        
    except Exception as e:
        print(f"‚ùå Error testing prompt optimization: {e}")
        return False

def main():
    """Run all self-forcing integration tests."""
    print("Testing Self-Forcing Integration...")
    print("=" * 60)
    
    tests = [
        ("Model Definition", test_self_forcing_model_definition),
        ("TextToVideoGenerator Integration", test_text_to_video_generator_integration),
        ("Content Model Preferences", test_content_model_preferences),
        ("Pipeline Compatibility", test_pipeline_compatibility),
        ("Model Path Mapping", test_model_path_mapping),
        ("Prompt Optimization", test_prompt_optimization)
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        print(f"\n--- {test_name} ---")
        try:
            if test_func():
                passed += 1
                print(f"‚úÖ {test_name} PASSED")
            else:
                failed += 1
                print(f"‚ùå {test_name} FAILED")
        except Exception as e:
            failed += 1
            print(f"‚ùå {test_name} ERROR: {e}")
    
    print(f"\n{'='*60}")
    print(f"SELF-FORCING INTEGRATION TEST SUMMARY")
    print(f"{'='*60}")
    print(f"Passed: {passed}")
    print(f"Failed: {failed}")
    print(f"Total:  {len(tests)}")
    
    if failed == 0:
        print("üéâ ALL SELF-FORCING INTEGRATION TESTS PASSED!")
        print("‚úÖ Self-forcing is properly integrated across all pipelines")
        print("‚úÖ Model download functionality should work")
        print("‚úÖ Video generation should work with self-forcing")
        return True
    else:
        print("‚ùå SOME SELF-FORCING INTEGRATION TESTS FAILED!")
        print("Additional fixes may be needed")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
